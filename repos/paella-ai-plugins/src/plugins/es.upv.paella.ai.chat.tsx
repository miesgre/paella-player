// import 'preact';
import { Events, type Caption, type PluginConfig } from '@asicupv/paella-core';
import PackagePluginModule from './PackagePluginModule';
import ChatIcon from "../icons/chat.svg?raw";

// import { ChatWebLLM } from "@langchain/community/chat_models/webllm";
// import { ChatOpenAI } from "@langchain/openai";
import { PreactButtonPlugin } from './PreactButtonPlugin/PreactButtonPlugin';
import type { ReactNode } from 'react';
import AIToolChat from '../ui/Chat';
import type { InitProgressCallback } from '@mlc-ai/web-llm';


export interface Chat {
    title: string;
    date: Date;
    messages: Array<{ role: string; text: string; processing?: boolean }>;
}

export interface Settings {
    modelType?: 'webllm' | 'openai';
    openAIURL?: string;
    openAIPasswd?: string;
    model?: string;
    contextWindowLength?: string;
    temperature?: number;
    maxTokens?: number;
    frequecyPenalty?: number;
    presencePenalty?: number;
    systemPrompt?: string;
}

export type AIChatPluginConfig = PluginConfig & {
    chat?: {
        enabled?: boolean;
        // model?: string;
        // baseUrl?: string;
        // promptMessage?: string;
    };
};


export default class AIChatPlugin extends PreactButtonPlugin  {
    showWelcomeMessage: boolean = true;
    webllmSettings: Settings = {};
    model: any = null;
    captionsRAG: string = "";
    captionsRAGNeedReload: boolean = true;


    getPluginModuleInstance() {
        return PackagePluginModule.Get();
    }
    

    get name() {
        return super.name || "es.upv.paella.ai.chat";
    }

    get config(): AIChatPluginConfig {
        return super.config as AIChatPluginConfig;
    }

    getAriaLabel() {
        return this.player.translate('AI Chat bot');
    }

    getDescription() {
        return this.getAriaLabel();
    }

    async load() {
        this.icon = this.player.getCustomPluginIcon(this.name, "chat") || ChatIcon;

        const buildCaptionsRAG = (captions: Caption) => {
            const formatTime = (seconds: number) => {
                const hours = Math.floor(seconds / 3600);
                const minutes = Math.floor((seconds % 3600) / 60);
                const secs = seconds % 60;
                
                const formattedHours = String(hours).padStart(2, '0');
                const formattedMinutes = String(minutes).padStart(2, '0');
                const formattedSeconds = String(secs).padStart(2, '0');
                
                return `${formattedHours}:${formattedMinutes}:${formattedSeconds}`;
            }

            this.captionsRAG = captions.cues.map(c => `${formatTime(c.start)}: ${c.captions.join(" ")}`).join("\n");
            this.captionsRAGNeedReload = true;
        }

        if (this.player.captionsCanvas?.captions?.length > 0) {
            buildCaptionsRAG(this.player.captionsCanvas?.captions[0])            
        }

        this.player.bindEvent(Events.CAPTIONS_CHANGED, ({captions}) => {            
            buildCaptionsRAG(captions[0])            
        });
    }    

    // async getHelp() {
    //     return {
    //         title: "Discover AI-Generated Content",
    //         description: "Use this button to access helpful content generated by artificial intelligence like summaries, key questions, and audio insights. Itâ€™s designed to save you time and help you understand faster."
    //     };
    // }

    async isEnabled(): Promise<boolean> {
        if (!(await super.isEnabled())) {
            return false;
        }

        this.webllmSettings = this.loadSettings();


        let data_available = this.config?.chat?.enabled;

        return !!data_available;
    }

    getReactNode(): ReactNode {
        return ( <AIToolChat className="ia-tools-tab-content" /> );
    }


    async loadModel(settings: Settings, progressCallback: InitProgressCallback) {
        this.player.log.info(`Reloading ${settings.modelType}/${settings.model} model (temperature=${settings.temperature}).`);
        let model = null;

        console.log(settings)
        if (settings.modelType === "webllm") {
            const { ChatWebLLM } = await import("@langchain/community/chat_models/webllm");
            

            model = new ChatWebLLM({
                model: settings.model!,
                temperature: settings.temperature,
                // max_tokens: settings.maxTokens,
                chatOptions: {                    
                    temperature: settings.temperature,
                    // context_window_size: parseInt(settings.contextWindowLength),
                    // frequency_penalty: settings.frequecyPenalty,                    
                    // presence_penalty: settings.presencePenalty,
                },
            });
            await model.initialize(progressCallback);
        }
        else if (settings.modelType === "openai") {
            const { ChatOpenAI } = await import("@langchain/openai");
            model = new ChatOpenAI({
                model: settings.model,
                configuration: {
                    baseURL: settings.openAIURL
                },
                apiKey: settings.openAIPasswd,
                temperature: settings.temperature,
                // max_tokens: settings.maxTokens,
                // frequencyPenalty: settings.frequecyPenalty,
                // presencePenalty: settings.presencePenalty            
            });
        }
        console.log("Model loaded: ", model);         
        this.model = model;
    }



    saveChats(chats: any) {
        localStorage.setItem(`${this.name}_chats`, JSON.stringify(chats));        
    }
    loadChats() {
        let savedChats = [];
        try {
            const savedChatsStr = localStorage.getItem(`${this.name}_chats`);
            savedChats = JSON.parse(savedChatsStr ?? '');
        } catch (e) { savedChats = [] }
        return savedChats ?? [];
    }

    saveSettings(settings: Settings) {
        localStorage.setItem(`${this.name}_settings`, JSON.stringify(settings));
        this.model = null;
    }

    loadSettings(): Settings {
        // TODO: Load default settings from config
        console.log("Loading settings for ", this.name);
        const defaultSettings: Settings = {
            modelType: "webllm",
            model: "Qwen2.5-3B-Instruct-q4f16_1-MLC", //"Phi-3-mini-4k-instruct-q4f16_1-MLC", //Llama-3.1-8B-Instruct-q4f32_1-MLC", "Qwen2.5-3B-Instruct-q4f16_1-MLC"
            openAIURL: "https://api.openai.com/v1",
            openAIPasswd: "",
            contextWindowLength: "1K",
            temperature: 1.0,
            maxTokens: 4000,
            frequecyPenalty: 0.0,
            presencePenalty: 0.0,

            systemPrompt: "You are a helpful assistant that can answer questions about the course content. You can also provide guidance on how to solve problems and help me understand the concepts better."
        }
        let savedSettings: Settings | null = null;
        try {
            const savedSettingsStr = localStorage.getItem(`${this.name}_settings`);
            if (savedSettingsStr !== null ) {
                savedSettings = JSON.parse(savedSettingsStr);
            }
        } catch (e) { 
            savedSettings = defaultSettings;
        }

        return savedSettings ?? defaultSettings;
    }

}
